import json
import math
import os
import gc
from typing import Any, Dict, List

from openai import OpenAI

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
llm = OpenAI(api_key=OPENAI_API_KEY or "")

def fetch_openai_chat(system_prompt: str, user_input: str) -> str:
    resp = llm.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_input},
        ],
        temperature=0.5,
        max_tokens=2000,
    )
    return resp.choices[0].message.content

def load_database(database_path: str = "data/cases.jsonl", max_items: int | None = None) -> List[Dict[str, Any]]:
    db: List[Dict[str, Any]] = []
    try:
        with open(database_path, encoding="utf8") as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                rec = json.loads(line)
                db.append({
                    "case_id": rec.get("case_id"),
                    "summaryOfCase": rec.get("summaryOfCase", ""),
                    "whole_case": rec.get("whole_case", {}),
                })
        return db if not max_items else db[:max_items]
    except Exception as e:
        print(f"Error loading database: {e}")
        return []

AGENT_PHASE1 = """
Ø£Ù†Øª Ù…Ø®ØªØµ Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø³Ø¹ÙˆØ¯ÙŠ ØªØ¨Ø­Ø« ÙÙŠ Ù‚Ø¶Ø§ÙŠØ§ Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø³Ø¹ÙˆØ¯ÙŠØ©.
Ø³ÙŠØªÙ… ØªØ²ÙˆÙŠØ¯Ùƒ Ø¨Ù‚Ø§Ø¦Ù…Ø© Ù‚Ø¶Ø§ÙŠØ§ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ case_id ÙˆÙ…Ù„Ø®Øµ Ù…ÙˆØ¬Ø² Ù„ÙƒÙ„ Ù‚Ø¶ÙŠØ©.
Ø³ÙŠÙ‚Ø¯Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ØªÙØ§ØµÙŠÙ„ Ù‚Ø¶ÙŠØ© ØªØ®ØµÙ‡. Ù…Ù‡Ù…ØªÙƒ: Ø§Ø±Ø¬Ø¹ Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„Ù‚Ø¶Ø§ÙŠØ§ Ø§Ù„Ù…Ø´Ø§Ø¨Ù‡Ø© Ù…Ø¹ Ø³Ø¨Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡.
Ø£Ø¹Ø¯ JSON ØµØ§Ù„Ø­ ÙÙ‚Ø· Ø¨Ø´ÙƒÙ„:
[{"case_id": 1, "PointOfSimilarity": "Ø§Ù„Ø³Ø¨Ø¨"}]
"""

AGENT_PHASE2 = """
Ø£Ù†Øª Ù…Ø®ØªØµ Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø³Ø¹ÙˆØ¯ÙŠ. Ø³ÙŠØªÙ… ØªØ²ÙˆÙŠØ¯Ùƒ Ø¨ØªÙØ§ØµÙŠÙ„ Ù‚Ø¶ÙŠØ© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ØŒ Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ Ø§Ù„Ù‚Ø¶Ø§ÙŠØ§ Ø§Ù„Ù…Ø´Ø§Ø¨Ù‡Ø©.
Ø£Ø¹Ø¯ JSON ÙÙ‚Ø· Ø¨Ø§Ù„Ù…ÙØ§ØªÙŠØ­:
1) "similar_cases": [{"case_id": 15,"summary": "Ù…Ù„Ø®Øµ < 50 ÙƒÙ„Ù…Ø© + ÙÙƒØ±Ø© Ø§Ù„Ø­ÙƒÙ…"}]
2) "Source": ÙƒÙŠÙ Ø³Ø§Ø¹Ø¯ØªÙƒ Ø§Ù„Ù‚Ø¶Ø§ÙŠØ§ Ø§Ù„Ù…Ø´Ø§Ø¨Ù‡Ø©.
3) "predicted_judgment": Ø§Ù„Ø­ÙƒÙ… Ø§Ù„Ø´Ø±Ø¹ÙŠ Ø§Ù„Ø±Ø³Ù…ÙŠ Ø§Ù„Ù…ÙØµÙ„.
"""

def init_model() -> Dict[str, Dict[str, str]]:
    return {"phase1": {"system": AGENT_PHASE1}, "phase2": {"system": AGENT_PHASE2}}

def find_matching_cases(initial_stage_model: Dict[str, str], case_data: List[Dict[str, Any]], query: str, batch_size: int = 100) -> List[Dict[str, Any]]:
    out: List[Dict[str, Any]] = []
    total_batches = math.ceil(len(case_data) / batch_size)
    for i in range(total_batches):
        batch = case_data[i * batch_size : (i + 1) * batch_size]
        batch_json = json.dumps(
            [{"case_id": r.get("case_id"), "summaryOfCase": r.get("summaryOfCase", "")} for r in batch],
            ensure_ascii=False,
            indent=2,
        )
        user_input = f"""
# Ø§Ù„Ù‚Ø¶Ø§ÙŠØ§ Ø§Ù„Ù…Ø¯Ø®Ù„Ø©
```json
{batch_json}
```

Ø§Ù„Ù‚Ø¶ÙŠØ© Ø§Ù„ØªÙŠ Ø³Ù†Ù‚Ø§Ø±Ù†Ù‡Ø§

{query}

Ø£Ø¹Ø¯ JSON ØµØ§Ù„Ø­ ÙÙ‚Ø·
"""
        try:
            content = fetch_openai_chat(initial_stage_model["system"], user_input)
            content = content.replace("```json", "").replace("```", "").strip()
            parsed = json.loads(content)
            if isinstance(parsed, list):
                out.extend(parsed)
        except Exception as e:
            print("Error response:", e)
    return out

def generate_final_judgment(final_stage_model: Dict[str, str], case_input: Dict[str, Any], matched_cases: List[Dict[str, Any]]) -> Dict[str, Any] | None:
    case_json = json.dumps(case_input, ensure_ascii=False, indent=2)
    matched_json = json.dumps(matched_cases, ensure_ascii=False, indent=2)
    user_input = f"""
ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù‚Ø¶ÙŠØ©:

{case_json}

Ø§Ù„Ù‚Ø¶Ø§ÙŠØ§ Ø§Ù„Ù…Ø´Ø§Ø¨Ù‡Ø©:

{matched_json}

Ø£Ø¹Ø¯ JSON ØµØ§Ù„Ø­ ÙÙ‚Ø·
"""
    try:
        content = fetch_openai_chat(final_stage_model["system"], user_input)
        content = content.replace("```json", "").replace("```", "").strip()
        return json.loads(content)
    except Exception as e:
        print("Error judgment:", e)
        return None

def _to_str_query(user_query: Any) -> str:
    # Normalize any payload (dict/list/str) into a clean string for LLM
    if isinstance(user_query, str):
        return user_query.strip()
    try:
        return json.dumps(user_query, ensure_ascii=False)
    except Exception:
        return str(user_query)

def run_virtual_agents(user_query: Any) -> Dict[str, Any]:
    """
    Orchestrates:
    1) similar-case lookup
    2) final judgment generation
    â€“ hardened against unhashable/slice errors by normalizing input.
    """
    try:
        model = init_model()
        database = load_database(max_items=100)
        if not database:
            return {"error": "Failed to load case database"}

        query_str = _to_str_query(user_query)
        print("ğŸ”„ Searching for similar cases...")
        matched = find_matching_cases(model["phase1"], database, query_str)

        if not matched:
            return {"error": "No similar cases found"}

        print("â³ Generating final judgment...")
        case_input = {"description": query_str}
        judgment = generate_final_judgment(model["phase2"], case_input, matched)
        if not judgment:
            return {"error": "Failed to generate judgment"}

        # Optional enrichment of similar cases with short summaries
        similar_cases_with_summaries: List[Dict[str, Any]] = []
        db_index = {str(x.get("case_id")): x for x in database}
        for m in matched:
            cid = str(m.get("case_id"))
            base = db_index.get(cid)
            if base:
                summary = base.get("summaryOfCase", "")
                short = summary[:50] + ("..." if len(summary) > 50 else "")
                similar_cases_with_summaries.append({
                    "case_id": cid,
                    "summary": short or "Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ù„Ø®Øµ Ù…ØªØ§Ø­",
                    "PointOfSimilarity": m.get("PointOfSimilarity", "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"),
                })

        del database, matched
        gc.collect()

        return {
            "similar_cases": similar_cases_with_summaries or judgment.get("similar_cases", []),
            "Source": judgment.get("Source", ""),
            "predicted_judgment": judgment.get("predicted_judgment", ""),
        }
    except Exception as e:
        print(f"Error in run_virtual_agents: {e}")
        gc.collect()
        return {"error": f"Failed to process request: {str(e)}"}
