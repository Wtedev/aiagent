import json
import openai
import math
import os
from openai import OpenAI
import gc

# Load environment variables
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

def load_database(database_path: str="data/cases.jsonl", max_items: int=None):
    database = []
    try:
        with open(database_path, encoding="utf8") as f:
            for line in f:
                if line.strip() == "":
                    continue
                rec = json.loads(line)
                database.append({
                    "case_id": rec["case_id"],
                    "summaryOfCase": rec["summaryOfCase"],
                    "whole_case": rec.get("whole_case", {})
                })
        return database if not max_items else database[:max_items]
    except Exception as e:
        print(f"Error loading database: {e}")
        return []



agent_phase1 = """
Ø£Ù†Øª Ù…Ø®ØªØµ Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø³Ø¹ÙˆØ¯ÙŠ ØªØ¨Ø­Ø« ÙÙŠ Ù‚Ø¶Ø§ÙŠØ§ Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø³Ø¹ÙˆØ¯ÙŠØ©.
Ø³ÙŠØªÙ… ØªØ²ÙˆÙŠØ¯Ùƒ Ø¨Ù‚Ø§Ø¦Ù…Ø© Ù‚Ø¶Ø§ÙŠØ§ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ case_id ÙˆÙ…Ù„Ø®Øµ Ù…ÙˆØ¬Ø² Ù„ÙƒÙ„ Ù‚Ø¶ÙŠØ©.
Ø³ÙŠÙ‚Ø¯Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ØªÙØ§ØµÙŠÙ„ Ù‚Ø¶ÙŠØ© ØªØ®ØµÙ‡ Ù…Ù‡Ù…ØªÙƒ ØªØ±Ø¬Ø¹ Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„Ù‚Ø¶Ø§ÙŠØ§ Ø§Ù„Ù…Ø´Ø§Ø¨Ù‡Ø© Ù…Ø¹ Ø°ÙƒØ± Ø³Ø¨Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡.
ØµÙŠØºØ© Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† JSON ÙÙ‚Ø·:
[{"case_id": 1, "PointOfSimilarity": "Ø§Ù„Ø³Ø¨Ø¨"}]
"""

agent_phase2 = """
Ø£Ù†Øª Ù…Ø®ØªØµ Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø³Ø¹ÙˆØ¯ÙŠ. Ø³ÙŠØªÙ… ØªØ²ÙˆÙŠØ¯Ùƒ Ø¨Ù‚Ø¶ÙŠØ© Ù…Ø¹ ÙƒØ§Ù…Ù„ ØªÙØ§ØµÙŠÙ„Ù‡Ø§ØŒ Ø¨Ø§Ù„Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ù‚Ø¶Ø§ÙŠØ§ Ù…Ø´Ø§Ø¨Ù‡Ø©.
Ù…Ù‡Ù…ØªÙƒ Ø¥ØµØ¯Ø§Ø± Ø­ÙƒÙ… Ù†Ù‡Ø§Ø¦ÙŠ Ù…ÙØµÙ„ Ù„Ù‚Ø¶ÙŠØ© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ØŒ ÙˆÙŠØ¬Ø¨ Ø£Ù† ÙŠØ´Ù…Ù„ Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ JSON ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ø§Ù„ØªØ§Ù„ÙŠØ©:

1. "similar_cases": Ù‚Ø§Ø¦Ù…Ø© Ù…Ù† Ø§Ù„Ù‚Ø¶Ø§ÙŠØ§ Ø§Ù„Ù…ØªØ´Ø§Ø¨Ù‡Ø© Ø¨ØµÙŠØºØ©:
   [{"case_id": 15,"summary": "Ù…Ù„Ø®Øµ Ø§Ù‚Ù„ Ù…Ù† 50 ÙƒÙ„Ù…Ø© ÙŠØµÙ ÙˆÙ‚Ø§Ø¦Ø¹ Ø§Ù„Ù‚Ø¶ÙŠØ©ØŒ Ù…ØªØ¨ÙˆØ¹Ù‹Ø§ Ø¨Ù…Ù„Ø®Øµ Ù…Ø®ØªØµØ± Ù„Ø­ÙƒÙ… Ø§Ù„Ù‚Ø§Ø¶ÙŠ ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù‚Ø¶ÙŠØ© (ÙÙƒØ±Ø© Ø§Ù„Ø­ÙƒÙ… Ø£Ùˆ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ÙÙ‚Ø·ØŒ Ø¨Ø¯ÙˆÙ† ØªÙØ§ØµÙŠÙ„ Ù…Ø·ÙˆÙ„Ø©)."}]

2. "Source": Ø´Ø±Ø­ Ù‚ØµÙŠØ± ÙŠÙˆØ¶Ø­ ÙƒÙŠÙ Ø³Ø§Ø¹Ø¯ØªÙƒ Ø§Ù„Ù‚Ø¶Ø§ÙŠØ§ Ø§Ù„Ù…Ø´Ø§Ø¨Ù‡Ø© ÙÙŠ Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ø­ÙƒÙ… (Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ¨Ø£Ø³Ù„ÙˆØ¨ ÙˆØ§Ø¶Ø­).

3. "predicted_judgment": Ø§Ù„Ù†Øµ Ø§Ù„ÙƒØ§Ù…Ù„ Ù„Ù„Ø­ÙƒÙ… Ø§Ù„Ø´Ø±Ø¹ÙŠ Ø§Ù„Ø±Ø³Ù…ÙŠØŒ ÙˆÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ù…ÙØµÙ„Ù‹Ø§ ÙˆÙŠÙÙƒØªØ¨ ÙƒØ£Ù†Ùƒ Ù‚Ø§Ø¶Ù Ø´Ø±Ø¹ÙŠ Ø¨Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©ØŒ Ù…Ø¹ Ø§ØªØ¨Ø§Ø¹ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„ØªØ§Ù„ÙŠØ©:

- Ø§Ø¨Ø¯Ø£ Ø¨Ù…Ù‚Ø¯Ù…Ø© Ø´Ø±Ø¹ÙŠØ© Ù…Ø«Ù„: "Ø§Ù„Ø­Ù…Ø¯ Ù„Ù„Ù‡ ÙˆØ­Ø¯Ù‡ØŒ ÙˆØ§Ù„ØµÙ„Ø§Ø© ÙˆØ§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„Ù‰ Ù…Ù† Ù„Ø§ Ù†Ø¨ÙŠ Ø¨Ø¹Ø¯Ù‡ØŒ ÙˆØ¨Ø¹Ø¯:"
- ÙŠØ¬Ø¨ Ø¹Ù„ÙŠÙƒ Ø§Ù„Ø§Ø³ØªØ´Ù‡Ø§Ø¯ Ø¥Ù„Ù‰ Ø§Ù„Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ø´Ø±Ø¹ÙŠØ© ÙˆØ§Ù„Ù†Ø¸Ø§Ù…ÙŠØ©ØŒ ÙˆØ§Ù„Ø£Ø­Ø§Ø¯ÙŠØ« ÙˆØ§Ù„Ø¢ÙŠØ§Øª Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©.
- ØµÙØº Ù…Ù†Ø·ÙˆÙ‚ Ø§Ù„Ø­ÙƒÙ… Ù…ÙØµÙ„Ù‹Ø§ ÙˆØ¨Ø§Ù„ØªØ±ØªÙŠØ¨ (Ø£ÙˆÙ„Ù‹Ø§ØŒ Ø«Ø§Ù†ÙŠÙ‹Ø§ØŒ Ø«Ø§Ù„Ø«Ù‹Ø§...).
- Ø§Ø´Ø±Ø­ Ø´Ø±Ø­ Ù‚ØµÙŠØ± ÙƒÙŠÙ Ø³Ø§Ø¹Ø¯ØªÙƒ Ø§Ù„Ù‚Ø¶Ø§ÙŠØ§Ø§Ù„Ù…ØªØ´Ø§Ø¨Ù‡Ø© ÙÙŠ Ø§ØµØ¯Ø§Ø± Ø­ÙƒÙ… Ù„Ù‚Ø¶ÙŠØ© Ø§Ù„ÙŠÙˆØ²Ø±"
- Ø§Ø®ØªÙ… Ø§Ù„Ø­ÙƒÙ… Ø¨ØµÙŠØºØ© Ø±Ø³Ù…ÙŠØ© Ù…Ø«Ù„: "ÙˆØ§Ù„Ù„Ù‡ Ø§Ù„Ù…ÙˆÙÙ‚ØŒ ÙˆØµÙ„Ù‰ Ø§Ù„Ù„Ù‡ Ø¹Ù„Ù‰ Ù†Ø¨ÙŠÙ†Ø§ Ù…Ø­Ù…Ø¯ ÙˆØ¹Ù„Ù‰ Ø¢Ù„Ù‡ ÙˆØµØ­Ø¨Ù‡ ÙˆØ³Ù„Ù… Ø£Ø¬Ù…Ø¹ÙŠÙ†."
- Ù„Ø§ ØªØ³ØªØ®Ø¯Ù… Ù‚ÙˆØ§Ù„Ø¨ Ø¬Ø§Ù‡Ø²Ø© Ø£Ùˆ Ø¹Ø¨Ø§Ø±Ø§Øª Ù…ÙƒØ±Ø±Ø©ØŒ Ø¨Ù„ Ø§Ø¬Ø¹Ù„ Ø§Ù„Ø­ÙƒÙ… Ø®Ø§ØµÙ‹Ø§ Ø¨Ø§Ù„Ù‚Ø¶ÙŠØ©.
{

}
Ø§Ù„Ø¢Ù†ØŒ Ù‡Ø°Ù‡ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù‚Ø¶ÙŠØ©:
{case_details}

ÙˆÙ‡Ø°Ù‡ Ø§Ù„Ù‚Ø¶Ø§ÙŠØ§ Ø§Ù„Ù…Ø´Ø§Ø¨Ù‡Ø© Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠØ©:
{similar_cases}

Ø£Ø®Ø±Ø¬ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø¨ØµÙŠØºØ© JSON ÙÙ‚Ø· ØªØªØ¶Ù…Ù† Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ø§Ù„Ø«Ù„Ø§Ø«Ø© Ø§Ù„Ù…Ø°ÙƒÙˆØ±Ø© Ø£Ø¹Ù„Ø§Ù‡.
"""



llm = OpenAI(api_key=OPENAI_API_KEY or "")

def fetch_openai_chat(context, input):
    response = llm.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": context},
            {"role": "user", "content": input}
        ],
        temperature=0.5,
        max_tokens=2000
    )
    return response.choices[0].message.content

def init_model():
    return {
        "phase1": {
            "system": agent_phase1
        },
        "phase2": {
            "system": agent_phase2
        }
    }



def find_matching_cases(initial_stage_model, case_data, query, batch_size=100, wait_timeout=3, progress=None):
    matching_cases  = []
    total_batches = math.ceil(len(case_data) / batch_size)

    for i in range(total_batches):
        batch = case_data[i*batch_size:(i+1)*batch_size]
        specfic_input = json.dumps([
            {"case_id": rec["case_id"], "summaryOfCase": rec["summaryOfCase"]} for rec in batch
        ], ensure_ascii=False, indent=2)

        user_input = f"""
# Ø§Ù„Ù‚Ø¶Ø§ÙŠØ§ Ø§Ù„Ù…Ø¯Ø®Ù„Ø©
```json
{specfic_input}
```
# Ø§Ù„Ù‚Ø¶ÙŠØ© Ø§Ù„ØªÙŠ Ø³Ù†Ù‚Ø§Ø±Ù†Ù‡Ø§
{query}
# Ù‚Ù… Ø¨Ø§Ø±Ø¬Ø§Ø¹ jsonØµØ­ÙŠØ­ ÙÙ‚Ø·
"""

        try:
            content = fetch_openai_chat(initial_stage_model["system"], user_input)
            content = content.replace("```json", "").replace("```", "").strip()
            matching_cases  += json.loads(content)
        except Exception as e:
            print("Error response:", e)
        if progress:
            progress.value += 1
    return matching_cases




def generate_final_judgment(final_stage_model, case_input, matched_cases):
    input_json = json.dumps(case_input, ensure_ascii=False, indent=2)
    matched_json = json.dumps(matched_cases, ensure_ascii=False, indent=2)

    user_input = f"""
# ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù‚Ø¶ÙŠØ©:
{input_json}
# Ø§Ù„Ù‚Ø¶Ø§ÙŠØ§ Ø§Ù„Ù…Ø´Ø§Ø¨Ù‡Ø©:
{matched_json}
# Ø±Ø¬Ø§Ø¡Ù‹ Ø£Ø¹Ø¯ ÙÙ‚Ø· JSON ØµØ­ÙŠØ­
"""
    try:
        content = fetch_openai_chat(final_stage_model["system"], user_input)
        content = content.replace("```json", "").replace("```", "").strip()
        return json.loads(content)
    except Exception as e:
        print("Error judgment:", e)
        return None

# ðŸš€ ADDING THE MISSING FUNCTION: run_virtual_agents
def run_virtual_agents(user_query: str):
    """
    Main function to run the virtual ruling system - EXACTLY as in test.py
    This function orchestrates the two-phase process:
    1. Find similar cases
    2. Generate final judgment
    """
    try:
        # Initialize the model (same as test.py)
        model = init_model()
        
        # Load the database (same as test.py) - ðŸš¨ MEMORY OPTIMIZATION: Limit to 100 cases
        database = load_database(max_items=100)
        
        if not database:
            return {"error": "Failed to load case database"}
        
        # Phase 1: Find matching cases (same as test.py)
        print("ðŸ”„ Searching for similar cases...")
        matched_cases = find_matching_cases(model["phase1"], database, user_query)
        
        if not matched_cases:
            return {"error": "No similar cases found"}
        
        # Phase 2: Generate final judgment (same as test.py)
        print("â³ Generating final judgment...")
        case_input = {"description": user_query.strip()}
        judgment = generate_final_judgment(model["phase2"], case_input, matched_cases)
        
        if not judgment:
            return {"error": "Failed to generate judgment"}
        
        # ðŸš¨ FIX: Create proper similar_cases with summaries (EXACTLY as in test.py)
        similar_cases_with_summaries = []
        for case in matched_cases:
            case_id = case.get('case_id', 'N/A')
            # Find the full case data from database
            full_case = next((c for c in database if str(c.get('case_id')) == str(case_id)), None)
            
            if full_case:
                summary = full_case.get('summaryOfCase', 'Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ù„Ø®Øµ Ù…ØªØ§Ø­')
                # Create summary like in test.py
                case_summary = f"{summary[:50]}{'...' if len(summary) > 50 else ''}"
                similar_cases_with_summaries.append({
                    "case_id": case_id,
                    "summary": case_summary,
                    "PointOfSimilarity": case.get('PointOfSimilarity', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')
                })
            else:
                similar_cases_with_summaries.append({
                    "case_id": case_id,
                    "summary": "Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ù„Ø®Øµ Ù…ØªØ§Ø­",
                    "PointOfSimilarity": case.get('PointOfSimilarity', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')
                })
        
        # ðŸš¨ MEMORY OPTIMIZATION: Force cleanup
        del database
        del matched_cases
        gc.collect()
        
        # Return the complete result (same structure as test.py)
        return {
            "similar_cases": similar_cases_with_summaries,
            "Source": judgment.get("Source", ""),
            "predicted_judgment": judgment.get("predicted_judgment", "")
        }
        
    except Exception as e:
        print(f"Error in run_virtual_agents: {e}")
        # ðŸš¨ MEMORY OPTIMIZATION: Force cleanup on error
        gc.collect()
        return {"error": f"Failed to process request: {str(e)}"}





