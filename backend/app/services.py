from __future__ import annotations
import os, functools, asyncio
from concurrent.futures import ThreadPoolExecutor

from dotenv import load_dotenv
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import FAISS

from backend.app.tasks import create_crew           # ÙŠØªÙˆÙ‚Ø¹ (llm, user_question, law_context)

load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
VECTOR_STORE_PATH = os.getenv("VECTOR_STORE_PATH")

# âŠ Ø«Ø¨Ù‘Øª Ù†Ù…ÙˆØ°Ø¬  LLM ÙˆØ§Ø­Ø¯ (ÙŠÙ…ÙƒÙ†Ùƒ ØªØºÙŠÙŠØ± Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙƒÙ…Ø§ ØªØ±ÙŠØ¯)
llm = ChatOpenAI( 
    model_name="gpt-4o",
    api_key=OPENAI_API_KEY,
    temperature=0.0
) 

# â‹ Ø­Ù…Ù‘Ù„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…ØªØ¬Ù‡Ø§Øª Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø©
embedding_model = OpenAIEmbeddings(api_key=OPENAI_API_KEY)
vector_db = FAISS.load_local(
    VECTOR_STORE_PATH,
    embeddings=embedding_model,
    allow_dangerous_deserialization=True
)

# Executor Ù„Ø¥Ø¨Ø¹Ø§Ø¯ Ø§Ù„Ø¹Ù…Ù„ Ø§Ù„Ø­Ø¸Ø±ÙŠ Ø¹Ù† Ù„ÙˆØ¨ FastAPI
_executor = ThreadPoolExecutor(max_workers=4)


# --------------------------------------------------------

async def run_chat(question: str, k: int = 5) -> str:
    # â€¦ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø³ÙŠØ§Ù‚ ÙˆØ¨Ù†Ø§Ø¡ Ø§Ù„Ù€ crew ÙƒÙ…Ø§ Ù‡Ùˆ â€¦
    docs = vector_db.similarity_search(question, k=k)
    law_context = "\n\n".join(d.page_content for d in docs)
    crew = create_crew(llm, question, law_context)


    loop = asyncio.get_event_loop()
    result = await loop.run_in_executor(_executor, crew.kickoff)

    # ğŸ”½ Ø­ÙˆÙÙ‘Ù„ Ø§Ù„Ø£Ù†ÙˆØ§Ø¹ ØºÙŠØ± Ø§Ù„Ù†ØµÙŠØ© Ø¥Ù„Ù‰ Ù†Øµ
    if isinstance(result, str):
        return result
    if hasattr(result, "raw"):
        return result.raw                       # CrewOutput.raw
    # Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‚Ø§Ø¦Ù…Ø© TaskOutput Ø®Ø° Ø§Ù„Ø£Ø®ÙŠØ±
    if isinstance(result, list) and result:
        last = result[-1]
        return getattr(last, "raw", str(last))

    # fallback Ø£Ø®ÙŠØ±
    return str(result)
async def run_chat_stream(question: str, k: int = 5):
    """
    Ù…ÙˆÙ„Ù‘Ø¯ Async ÙŠØ¨Ø« Ø§Ù„Ø±Ø¯ ØªØ¯Ø±ÙŠØ¬ÙŠÙ‹Ø§ (Ø¥Ø°Ø§ ÙƒØ§Ù† Crew Ø£Ùˆ Ø§Ù„Ù€ LLM ÙŠØ¯Ø¹Ù… Ø°Ù„Ùƒ).
    """
    docs = vector_db.similarity_search(question, k=k)
    law_context = "\n\n".join(d.page_content for d in docs)

    crew = create_crew(llm, question, law_context)

    # Ø¥Ù† Ù„Ù… ÙŠÙƒÙ† Ù„Ø¯ÙŠÙƒ stream Ø­Ù‚ÙŠÙ‚ÙŠ ÙŠÙ…ÙƒÙ†Ùƒ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø¯ÙØ¹Ø© ÙˆØ§Ø­Ø¯Ø©
    answer = await run_chat(question, k)
    yield answer